# UC Berkeley Data Science W261: Machine Learning at Scale

This repository contains my coursework for UC Berkeleyâ€™s Data Science W261 (MIDS program). The course covers scalable machine learning concepts and practical skills for working with large datasets using distributed computing frameworks, Python, and essential data science tools.

## Course Summary & Learning Objectives
- Develop proficiency in scalable data science and machine learning using Python and distributed systems (e.g., Hadoop, MapReduce).
- Apply object-oriented programming (OOP) and modular design principles.
- Work with data structures, functions, and modules for large-scale data processing.
- Use Jupyter Notebooks and Python scripts for interactive analysis and reporting.
- Practice data cleaning, transformation, and exploratory data analysis (EDA) on large datasets.
- Gain experience with version control (Git/GitHub) and collaborative workflows.

## Major Projects & Assignments

### Final Project: Large-Scale Data Analysis
**Location:** `Final Project/w261_Section2_Group3/`

**Description:**
Team-based project focused on scalable data analysis and machine learning. Includes exploratory data analysis (EDA), feature engineering, and distributed processing using Python scripts and Jupyter Notebooks. The project demonstrates the application of course concepts to real-world, large-scale datasets.

**Key Skills:**
Distributed data processing, EDA, feature engineering, collaborative coding, reporting, and reproducibility.

### Homework Assignments
**Location:** `Homework/`

Assignments are organized by week and cover a range of topics:

- **HW1:** MapReduce basics, word count, and aggregation tasks using Python scripts and shell commands.
- **HW2:** Naive Bayes classification, data wrangling, and evaluation using custom mappers and reducers.
- **HW3:** Advanced MapReduce, sorting, and partitioning techniques for large datasets.

**Key Skills:**
Distributed computing, Python scripting, Hadoop/MapReduce, data wrangling, algorithmic thinking, and evaluation metrics.

### Live Session Demos
**Location:** `Live Session Demos/`

Contains in-class demo scripts and notebooks illustrating key concepts, such as MapReduce, data partitioning, and distributed sorting.

**Key Skills:**
Hands-on practice with distributed algorithms, debugging, and collaborative problem-solving.

## Technologies Used
- Python 3.x
- Jupyter Notebooks
- pandas, numpy, matplotlib
- Hadoop/MapReduce
- Git & GitHub

## How to Run
1. Clone the repository.
2. Set up a Python virtual environment and install dependencies (see assignment or project-specific requirements).
3. Open and run Jupyter Notebooks for each assignment or project.
4. For MapReduce scripts, follow instructions in assignment folders to run Python scripts with Hadoop or locally.

## Reflection
This portfolio demonstrates my growth in scalable programming, distributed data processing, and machine learning. It serves as a foundation for advanced data science coursework and real-world applications involving large-scale data.